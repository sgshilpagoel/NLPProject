{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_Spa_Eng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "djhFyrSi9BkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import nltk\n",
        "import keras\n",
        "import string as st\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from google.colab import files\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9avi6blXMuuf",
        "colab_type": "text"
      },
      "source": [
        "***Run the code in google colab.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pghSJcM3Ho8a",
        "colab_type": "text"
      },
      "source": [
        "# ***Neural Machine Translation from Spanish to english using encoder decoder sequence model.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMAzzF_wJ1TC",
        "colab_type": "text"
      },
      "source": [
        "# ***Dataset is restricted to 35000 records apporx. for this execution (total dataset is of 174481 records).***\n",
        "\n",
        "I have generated the output in the csv file 'predicted.csv' which will be visible in the left pane on refreshing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI7AZzSBOxn_",
        "colab_type": "code",
        "outputId": "abae61ad-6a70-4e44-f7a8-af51045def5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# convert data into dataframe  \n",
        "data = pd.read_csv('spa.txt', delimiter='\\t', names=['English', 'Spanish'], usecols=[0,1])\n",
        "dataCopy=data\n",
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Spanish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Ve.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vete.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vaya.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Váyase.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hola.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English  Spanish\n",
              "0     Go.      Ve.\n",
              "1     Go.    Vete.\n",
              "2     Go.    Vaya.\n",
              "3     Go.  Váyase.\n",
              "4     Hi.    Hola."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze1lSC5gPcGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape\n",
        "# restrict dataset to approx. 35000 records\n",
        "dataLimit = np.random.rand(len(dataCopy)) <= 0.28\n",
        "limitDataset=dataCopy[dataLimit]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDRFyiuZPwqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aeee8d9f-f168-43aa-9aa2-978abdd84fc7"
      },
      "source": [
        "limitDataset.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34482, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1j23SeBVWs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7718a8fe-f4c3-4759-fb3c-f6d3b6a6e304"
      },
      "source": [
        "#keras based tokenizer is used to map words to integer\n",
        "tokenizerEn=Tokenizer()\n",
        "tokenizerFr=Tokenizer()\n",
        "\n",
        "tokenizerEn.fit_on_texts(limitDataset['English'].to_numpy())\n",
        "vocabSizeEn = len(tokenizerEn.word_index) + 1\n",
        "\n",
        "tokenizerFr.fit_on_texts(limitDataset['Spanish'].to_numpy())\n",
        "vocabSizeFr = len(tokenizerFr.word_index) + 1\n",
        "\n",
        "print('Vocabulary Size: English ', vocabSizeEn, \"Spanish \", vocabSizeFr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: English  8609 Spanish  15324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTWGjh3bQZwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecab1ba4-e684-4fe0-991b-8228ff55f64a"
      },
      "source": [
        "#Data preprocessing to clean the data and get the maximum sized length of sentences from both languages\n",
        "maxLenEn = 0\n",
        "maxLenFr = 0\n",
        "for index, row in limitDataset.iterrows():\n",
        "    row['English']=row['English'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['English'].split())>maxLenEn:\n",
        "        maxLenEn=len(row['English'].split())\n",
        "    row['Spanish']=row['Spanish'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['Spanish'].split())>maxLenFr:\n",
        "        maxLenFr=len(row['Spanish'].split())  \n",
        "print(\"Maximum sized length : English \",maxLenEn,\"Spanish \", maxLenFr )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum sized length : English  47 Spanish  49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aZ9oy4BPYEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b2c49ec-79b1-41fe-8560-5e97e68be785"
      },
      "source": [
        "# we will split the data to keep 70:30 ratio for training and test data\n",
        "splitData = np.random.rand(len(limitDataset)) <= 0.7\n",
        "trainData = limitDataset[splitData]\n",
        "testData = limitDataset[~splitData]\n",
        "#check the data count in training set and test set\n",
        "print(\"Training Data: \",trainData.shape,\" Test data: \",testData.shape)\n",
        "# Data in to numpy array conversion\n",
        "trainDataNP=trainData.to_numpy()\n",
        "testDataNP=testData.to_numpy()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:  (24077, 2)  Test data:  (10405, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHEh1q55KMLh",
        "colab_type": "text"
      },
      "source": [
        "**Data encoding is done i.e. converting text to ids and add padding to make all sequences of same length. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDokS3TrX3vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataEncoder(allData, lanTokenizer, length):\n",
        "    encodedData = lanTokenizer.texts_to_sequences(allData)\n",
        "    paddedData = pad_sequences(encodedData, maxlen=length, padding='post')\n",
        "    return paddedData\n",
        "\n",
        "trainFr = dataEncoder(trainDataNP[:, 1],tokenizerFr,maxLenFr)\n",
        "trainEn = dataEncoder(trainDataNP[:, 0],tokenizerEn,maxLenEn)\n",
        "testFr = dataEncoder(testDataNP[:, 1],tokenizerFr,maxLenFr)\n",
        "testEn = dataEncoder(testDataNP[:, 0],tokenizerEn,maxLenEn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEBL70vrw7yR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f2818dd-c034-41a7-ded2-d929c364e050"
      },
      "source": [
        "print(trainFr.shape, testFr.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24077, 49) (10405, 49)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr1JGCSS2MHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "da54eca5-ed15-4af6-bb8f-2e33651e631e"
      },
      "source": [
        "#Sequence model\n",
        "def sequenceModel(vocabFr, vocabEn, maxFr, maxEn, units):\n",
        "    seqModel = Sequential()\n",
        "    seqModel.add(Embedding(vocabFr, units, input_length=maxFr, mask_zero=True))\n",
        "    seqModel.add(LSTM(units))\n",
        "    seqModel.add(RepeatVector(maxEn))\n",
        "    seqModel.add(LSTM(units, return_sequences=True))\n",
        "    seqModel.add(Dense(vocabEn, activation='softmax'))\n",
        "    return seqModel\n",
        "\n",
        "seqModel = sequenceModel(vocabSizeFr, vocabSizeEn, maxLenFr, maxLenEn, 256)\n",
        "rmsOptimizer = optimizers.RMSprop(lr=0.01)\n",
        "seqModel.compile(optimizer=rmsOptimizer, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sye8mavR44sm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "0cf8276b-26f4-4878-8c2c-73ccbc000922"
      },
      "source": [
        "modelPrediction = seqModel.fit(trainFr, trainEn.reshape(trainEn.shape[0], trainEn.shape[1], 1),epochs=15, batch_size=256, validation_split = 0.2, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 19261 samples, validate on 4816 samples\n",
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "19261/19261 [==============================] - 28s 1ms/step - loss: 1.2538 - val_loss: 1.7009\n",
            "Epoch 2/15\n",
            "19261/19261 [==============================] - 18s 944us/step - loss: 0.7348 - val_loss: 1.7458\n",
            "Epoch 3/15\n",
            "19261/19261 [==============================] - 18s 953us/step - loss: 0.6791 - val_loss: 1.4919\n",
            "Epoch 4/15\n",
            "19261/19261 [==============================] - 18s 939us/step - loss: 0.6101 - val_loss: 1.5868\n",
            "Epoch 5/15\n",
            "19261/19261 [==============================] - 18s 945us/step - loss: 0.5442 - val_loss: 1.5290\n",
            "Epoch 6/15\n",
            "19261/19261 [==============================] - 18s 947us/step - loss: 0.4785 - val_loss: 1.6430\n",
            "Epoch 7/15\n",
            "19261/19261 [==============================] - 18s 953us/step - loss: 0.4187 - val_loss: 1.4227\n",
            "Epoch 8/15\n",
            "19261/19261 [==============================] - 18s 938us/step - loss: 0.3643 - val_loss: 1.4821\n",
            "Epoch 9/15\n",
            "19261/19261 [==============================] - 18s 939us/step - loss: 0.3160 - val_loss: 1.4053\n",
            "Epoch 10/15\n",
            "19261/19261 [==============================] - 18s 944us/step - loss: 0.2724 - val_loss: 1.5857\n",
            "Epoch 11/15\n",
            "19261/19261 [==============================] - 18s 942us/step - loss: 0.2356 - val_loss: 1.5410\n",
            "Epoch 12/15\n",
            "19261/19261 [==============================] - 18s 953us/step - loss: 0.2032 - val_loss: 1.5646\n",
            "Epoch 13/15\n",
            "19261/19261 [==============================] - 18s 955us/step - loss: 0.1763 - val_loss: 1.6628\n",
            "Epoch 14/15\n",
            "19261/19261 [==============================] - 18s 948us/step - loss: 0.1532 - val_loss: 1.6586\n",
            "Epoch 15/15\n",
            "19261/19261 [==============================] - 18s 941us/step - loss: 0.1344 - val_loss: 1.6661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUE8e54f54if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get predictions for text data \n",
        "testPrediction = seqModel.predict_classes(testFr.reshape((testFr.shape[0],testFr.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64hf0jpJ8IBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## data decoder Convert mapped words in to normal words\n",
        "def wordConversion(word_index, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == word_index:\n",
        "            return word\n",
        "    return None\n",
        "    \n",
        "def dataDecoder(prediction):\n",
        "    textPredicted=list()\n",
        "    for sentence in prediction:\n",
        "        sentenceConverted = list()\n",
        "        for word_index in range(len(sentence)):\n",
        "            word = wordConversion(sentence[word_index], tokenizerEn)\n",
        "            if word_index > 0:\n",
        "                if (word == wordConversion(sentence[word_index-1], tokenizerEn)) or (word == None):\n",
        "                    sentenceConverted.append('')\n",
        "                else:\n",
        "                    sentenceConverted.append(word)\n",
        "\n",
        "            else:\n",
        "                if(word == None):\n",
        "                    sentenceConverted.append('')\n",
        "                else:\n",
        "                    sentenceConverted.append(word)            \n",
        "\n",
        "        textPredicted.append(' '.join(sentenceConverted))\n",
        "        \n",
        "    return textPredicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhxXezP9vQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calling data decoder for the predictions\n",
        "predictedText = dataDecoder(testPrediction)\n",
        "predictedDataframe = pd.DataFrame({'Spanish text': testData['Spanish'],' Expected text' : testData['English'], 'Predicted text' : predictedText})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSruLeXrG969",
        "colab_type": "text"
      },
      "source": [
        "# ***Data after conversion from German to english i.e. both the expected and predicted english text***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIPzs9tI-Bke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "bbb12f04-b00c-4f22-a235-b55174ee8dc1"
      },
      "source": [
        "\n",
        "predictedDataframe.head(10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spanish text</th>\n",
              "      <th>Expected text</th>\n",
              "      <th>Predicted text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ve</td>\n",
              "      <td>go</td>\n",
              "      <td>you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>salte</td>\n",
              "      <td>jump</td>\n",
              "      <td>lets take                                     ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>continúe</td>\n",
              "      <td>go on</td>\n",
              "      <td>can you me                                    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>hola</td>\n",
              "      <td>hello</td>\n",
              "      <td>speak take fatter                             ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>corría</td>\n",
              "      <td>i ran</td>\n",
              "      <td>he closely                                    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>ve ahora mismo</td>\n",
              "      <td>go now</td>\n",
              "      <td>were it right now                             ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>renuncié</td>\n",
              "      <td>i quit</td>\n",
              "      <td>ate abandoned                                 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>lloraba</td>\n",
              "      <td>i wept</td>\n",
              "      <td>he come                                       ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>¡ni en pedo</td>\n",
              "      <td>no way</td>\n",
              "      <td>he fell in  account                           ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>llámame</td>\n",
              "      <td>call me</td>\n",
              "      <td>come me in                                    ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Spanish text  ...                                     Predicted text\n",
              "0                ve  ...  you                                              \n",
              "19            salte  ...  lets take                                     ...\n",
              "26         continúe  ...  can you me                                    ...\n",
              "27             hola  ...  speak take fatter                             ...\n",
              "33           corría  ...  he closely                                    ...\n",
              "51   ve ahora mismo  ...  were it right now                             ...\n",
              "76         renuncié  ...  ate abandoned                                 ...\n",
              "79          lloraba  ...  he come                                       ...\n",
              "95      ¡ni en pedo  ...  he fell in  account                           ...\n",
              "122         llámame  ...  come me in                                    ...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxI95pCaGo_g",
        "colab_type": "text"
      },
      "source": [
        "# ***Using corpus bleu function to calculate the Bleu score for data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTJqNco-_MWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0eb1531f-3f92-4e1d-dae1-9d3ff0b44180"
      },
      "source": [
        "print('BLEU score using corpus bleu function:',corpus_bleu(testDataNP[:,0], predictedText))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score using corpus bleu function: 0.6209628093533119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8vuCXQhIM46",
        "colab_type": "text"
      },
      "source": [
        "## ***Generating the csv file for predicted output***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdSEKp-fIF5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedDataframe.to_csv('predicted.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}