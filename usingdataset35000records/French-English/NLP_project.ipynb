{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NLP_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "djhFyrSi9BkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import nltk\n",
        "import keras\n",
        "import string as st\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from google.colab import files\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9avi6blXMuuf",
        "colab_type": "text"
      },
      "source": [
        "***Run the code in google colab.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pghSJcM3Ho8a",
        "colab_type": "text"
      },
      "source": [
        "# ***Neural Machine Translation from french to english using encoder decoder sequence model.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMAzzF_wJ1TC",
        "colab_type": "text"
      },
      "source": [
        "# ***Dataset is restricted to 35000 records apporx. for this execution (total dataset is of 174481 records).***\n",
        "\n",
        "I have generated the output in the csv file 'predicted.csv' which will be visible in the left pane on refreshing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI7AZzSBOxn_",
        "colab_type": "code",
        "outputId": "93aaba6a-e423-442d-f0d3-4a77652252ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# convert data into dataframe  \n",
        "data = pd.read_csv('fra.txt', delimiter='\\t', names=['English', 'French'], usecols=[0,1])\n",
        "dataCopy=data\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English    French\n",
              "0     Go.      Va !\n",
              "1     Hi.   Salut !\n",
              "2     Hi.    Salut.\n",
              "3    Run!   Cours !\n",
              "4    Run!  Courez !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze1lSC5gPcGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape\n",
        "# restrict dataset to 34794 records\n",
        "dataLimit = np.random.rand(len(dataCopy)) <= 0.2\n",
        "limitDataset=dataCopy[dataLimit]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDRFyiuZPwqd",
        "colab_type": "code",
        "outputId": "3eaa96d6-6982-4d5b-d40a-db8ac486a0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "limitDataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34798, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1j23SeBVWs3",
        "colab_type": "code",
        "outputId": "335cc9d0-142a-455f-e47d-fbaac943b50e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#keras based tokenizer is used to map words to integer\n",
        "tokenizerEn=Tokenizer()\n",
        "tokenizerFr=Tokenizer()\n",
        "\n",
        "tokenizerEn.fit_on_texts(limitDataset['English'].to_numpy())\n",
        "vocabSizeEn = len(tokenizerEn.word_index) + 1\n",
        "\n",
        "tokenizerFr.fit_on_texts(limitDataset['French'].to_numpy())\n",
        "vocabSizeFr = len(tokenizerFr.word_index) + 1\n",
        "\n",
        "print('Vocabulary Size: English ', vocabSizeEn, \"French \", vocabSizeFr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: English  8153 French  14823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTWGjh3bQZwe",
        "colab_type": "code",
        "outputId": "5ff2a52a-fb67-4111-a295-d1ee984838df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Data preprocessing to clean the data and get the maximum sized length of sentences from both languages\n",
        "maxLenEn = 0\n",
        "maxLenFr = 0\n",
        "for index, row in limitDataset.iterrows():\n",
        "    row['English']=row['English'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['English'].split())>maxLenEn:\n",
        "        maxLenEn=len(row['English'].split())\n",
        "    row['French']=row['French'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['French'].split())>maxLenFr:\n",
        "        maxLenFr=len(row['French'].split())  \n",
        "print(\"Maximum sized length : English \",maxLenEn,\"French \", maxLenFr )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum sized length : English  47 French  51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aZ9oy4BPYEh",
        "colab_type": "code",
        "outputId": "a54ceb66-1edb-42fd-a985-0f9365918c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# we will split the data to keep 70:30 ratio for training and test data\n",
        "splitData = np.random.rand(len(limitDataset)) <= 0.7\n",
        "trainData = limitDataset[splitData]\n",
        "testData = limitDataset[~splitData]\n",
        "#check the data count in training set and test set\n",
        "print(\"Training Data: \",trainData.shape,\" Test data: \",testData.shape)\n",
        "# Data in to numpy array conversion\n",
        "trainDataNP=trainData.to_numpy()\n",
        "testDataNP=testData.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:  (24445, 2)  Test data:  (10353, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHEh1q55KMLh",
        "colab_type": "text"
      },
      "source": [
        "**Data encoding is done i.e. converting text to ids and add padding to make all sequences of same length. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDokS3TrX3vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataEncoder(allData, lanTokenizer, length):\n",
        "    encodedData = lanTokenizer.texts_to_sequences(allData)\n",
        "    paddedData = pad_sequences(encodedData, maxlen=length, padding='post')\n",
        "    return paddedData\n",
        "\n",
        "trainFr = dataEncoder(trainDataNP[:, 1],tokenizerFr,maxLenFr)\n",
        "trainEn = dataEncoder(trainDataNP[:, 0],tokenizerEn,maxLenEn)\n",
        "testFr = dataEncoder(testDataNP[:, 1],tokenizerFr,maxLenFr)\n",
        "testEn = dataEncoder(testDataNP[:, 0],tokenizerEn,maxLenEn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEBL70vrw7yR",
        "colab_type": "code",
        "outputId": "c490f20f-f02a-4d89-bd8e-df55fd49cde7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(trainFr.shape, testFr.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24445, 51) (10353, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr1JGCSS2MHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sequence model\n",
        "def sequenceModel(vocabFr, vocabEn, maxFr, maxEn, units):\n",
        "    seqModel = Sequential()\n",
        "    seqModel.add(Embedding(vocabFr, units, input_length=maxFr, mask_zero=True))\n",
        "    seqModel.add(LSTM(units))\n",
        "    seqModel.add(RepeatVector(maxEn))\n",
        "    seqModel.add(LSTM(units, return_sequences=True))\n",
        "    seqModel.add(Dense(vocabEn, activation='softmax'))\n",
        "    return seqModel\n",
        "\n",
        "seqModel = sequenceModel(vocabSizeFr, vocabSizeEn, maxLenFr, maxLenEn, 256)\n",
        "rmsOptimizer = optimizers.RMSprop(lr=0.01)\n",
        "seqModel.compile(optimizer=rmsOptimizer, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sye8mavR44sm",
        "colab_type": "code",
        "outputId": "a088f728-4086-44b7-c332-a68a52d631d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "modelPrediction = seqModel.fit(trainFr, trainEn.reshape(trainEn.shape[0], trainEn.shape[1], 1),epochs=15, batch_size=256, validation_split = 0.2, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 19556 samples, validate on 4889 samples\n",
            "Epoch 1/15\n",
            "19556/19556 [==============================] - 25s 1ms/step - loss: 1.2311 - val_loss: 1.6975\n",
            "Epoch 2/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.6988 - val_loss: 1.7266\n",
            "Epoch 3/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.6453 - val_loss: 1.4167\n",
            "Epoch 4/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.5787 - val_loss: 1.3556\n",
            "Epoch 5/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.5181 - val_loss: 1.3581\n",
            "Epoch 6/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.4655 - val_loss: 1.3467\n",
            "Epoch 7/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.4125 - val_loss: 1.4934\n",
            "Epoch 8/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.3653 - val_loss: 1.4296\n",
            "Epoch 9/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.3200 - val_loss: 1.5285\n",
            "Epoch 10/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.2810 - val_loss: 1.5496\n",
            "Epoch 11/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.2458 - val_loss: 1.6247\n",
            "Epoch 12/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.2150 - val_loss: 1.5618\n",
            "Epoch 13/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.1897 - val_loss: 1.7057\n",
            "Epoch 14/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.1672 - val_loss: 1.7087\n",
            "Epoch 15/15\n",
            "19556/19556 [==============================] - 22s 1ms/step - loss: 0.1474 - val_loss: 1.6926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUE8e54f54if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get predictions for text data \n",
        "testPrediction = seqModel.predict_classes(testFr.reshape((testFr.shape[0],testFr.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64hf0jpJ8IBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## data decoder Convert mapped words in to normal words\n",
        "def wordConversion(word_index, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == word_index:\n",
        "            return word\n",
        "    return None\n",
        "    \n",
        "def dataDecoder(prediction):\n",
        "    textPredicted=list()\n",
        "    for sentence in prediction:\n",
        "        sentenceConverted = list()\n",
        "        for word_index in range(len(sentence)):\n",
        "            word = wordConversion(sentence[word_index], tokenizerEn)\n",
        "            if word_index > 0:\n",
        "                if (word == wordConversion(sentence[word_index-1], tokenizerEn)) or (word == None):\n",
        "                    sentenceConverted.append('')\n",
        "                else:\n",
        "                    sentenceConverted.append(word)\n",
        "\n",
        "            else:\n",
        "                if(word == None):\n",
        "                    sentenceConverted.append('')\n",
        "                else:\n",
        "                    sentenceConverted.append(word)            \n",
        "\n",
        "        textPredicted.append(' '.join(sentenceConverted))\n",
        "        \n",
        "    return textPredicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhxXezP9vQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calling data decoder for the predictions\n",
        "predictedText = dataDecoder(testPrediction)\n",
        "predictedDataframe = pd.DataFrame({'French text': testData['French'],' Expected text' : testData['English'], 'Predicted text' : predictedText})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSruLeXrG969",
        "colab_type": "text"
      },
      "source": [
        "# ***Data after conversion from french to english i.e. both the expected and predicted english text***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIPzs9tI-Bke",
        "colab_type": "code",
        "outputId": "d5832405-b80e-4a2e-ee6d-054c2c565efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "\n",
        "predictedDataframe.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>French text</th>\n",
              "      <th>Expected text</th>\n",
              "      <th>Predicted text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salut</td>\n",
              "      <td>hi</td>\n",
              "      <td>stop the                                      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>au feu</td>\n",
              "      <td>fire</td>\n",
              "      <td>i  turned the                                 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>salut</td>\n",
              "      <td>hello</td>\n",
              "      <td>stop the                                      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>oh non</td>\n",
              "      <td>oh no</td>\n",
              "      <td>oh to up                                      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>sans façons</td>\n",
              "      <td>no way</td>\n",
              "      <td>i was it                                      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>nous lemportâmes</td>\n",
              "      <td>we won</td>\n",
              "      <td>it we                                         ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>soyez justes</td>\n",
              "      <td>be fair</td>\n",
              "      <td>be prepared                                   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>soyez gentils</td>\n",
              "      <td>be nice</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>entre</td>\n",
              "      <td>come in</td>\n",
              "      <td>get inside                                    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>laissele tomber</td>\n",
              "      <td>drop it</td>\n",
              "      <td>its left                                      ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          French text  ...                                     Predicted text\n",
              "1              salut   ...  stop the                                      ...\n",
              "7             au feu   ...  i  turned the                                 ...\n",
              "19             salut   ...  stop the                                      ...\n",
              "25            oh non   ...  oh to up                                      ...\n",
              "60       sans façons   ...  i was it                                      ...\n",
              "74   nous lemportâmes  ...  it we                                         ...\n",
              "83      soyez justes   ...  be prepared                                   ...\n",
              "92     soyez gentils   ...   be                                              \n",
              "101            entre   ...  get inside                                    ...\n",
              "109  laissele tomber   ...  its left                                      ...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxI95pCaGo_g",
        "colab_type": "text"
      },
      "source": [
        "# ***Using corpus bleu function to calculate the Bleu score for data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTJqNco-_MWj",
        "colab_type": "code",
        "outputId": "3483d61b-47cf-423f-ff1c-cd2744b290ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print('BLEU score using corpus bleu function:',corpus_bleu(testDataNP[:,0], predictedText))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score using corpus bleu function: 0.6159744457076815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8vuCXQhIM46",
        "colab_type": "text"
      },
      "source": [
        "## ***Generating the csv file for predicted output***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdSEKp-fIF5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedDataframe.to_csv('predicted.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}