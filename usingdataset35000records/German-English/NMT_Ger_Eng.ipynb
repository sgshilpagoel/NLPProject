{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_Ger_Eng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "djhFyrSi9BkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import nltk\n",
        "import keras\n",
        "import string as st\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from google.colab import files\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9avi6blXMuuf",
        "colab_type": "text"
      },
      "source": [
        "***Run the code in google colab.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pghSJcM3Ho8a",
        "colab_type": "text"
      },
      "source": [
        "# ***Neural Machine Translation from German to english using encoder decoder sequence model.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMAzzF_wJ1TC",
        "colab_type": "text"
      },
      "source": [
        "# ***Dataset is restricted to 35000 records apporx. for this execution (total dataset is of 174481 records).***\n",
        "\n",
        "I have generated the output in the csv file 'predicted.csv' which will be visible in the left pane on refreshing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI7AZzSBOxn_",
        "colab_type": "code",
        "outputId": "249def81-1493-489a-8d8e-a322ef5f1f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# convert data into dataframe  \n",
        "data = pd.read_csv('deu.txt', delimiter='\\t', names=['English', 'German'], usecols=[0,1])\n",
        "dataCopy=data\n",
        "data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>German</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hallo!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Grüß Gott!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lauf!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Potzdonner!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Donnerwetter!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English         German\n",
              "0     Hi.         Hallo!\n",
              "1     Hi.     Grüß Gott!\n",
              "2    Run!          Lauf!\n",
              "3    Wow!    Potzdonner!\n",
              "4    Wow!  Donnerwetter!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze1lSC5gPcGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape\n",
        "# restrict dataset to 35000 records\n",
        "dataLimit = np.random.rand(len(dataCopy)) <= 0.18\n",
        "limitDataset=dataCopy[dataLimit]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDRFyiuZPwqd",
        "colab_type": "code",
        "outputId": "16766fda-c299-4c26-ebcc-4a86c9f84205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "limitDataset.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36938, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1j23SeBVWs3",
        "colab_type": "code",
        "outputId": "3902b678-d1af-48d1-9227-b89725eeffec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#keras based tokenizer is used to map words to integer\n",
        "tokenizerEn=Tokenizer()\n",
        "tokenizerFr=Tokenizer()\n",
        "\n",
        "tokenizerEn.fit_on_texts(limitDataset['English'].to_numpy())\n",
        "vocabSizeEn = len(tokenizerEn.word_index) + 1\n",
        "\n",
        "tokenizerFr.fit_on_texts(limitDataset['German'].to_numpy())\n",
        "vocabSizeFr = len(tokenizerFr.word_index) + 1\n",
        "\n",
        "print('Vocabulary Size: English ', vocabSizeEn, \"German \", vocabSizeFr)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: English  8654 German  15025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTWGjh3bQZwe",
        "colab_type": "code",
        "outputId": "f93eec2a-0c0e-4e9a-aff8-3649ff3475b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Data preprocessing to clean the data and get the maximum sized length of sentences from both languages\n",
        "maxLenEn = 0\n",
        "maxLenFr = 0\n",
        "for index, row in limitDataset.iterrows():\n",
        "    row['English']=row['English'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['English'].split())>maxLenEn:\n",
        "        maxLenEn=len(row['English'].split())\n",
        "    row['German']=row['German'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['German'].split())>maxLenFr:\n",
        "        maxLenFr=len(row['German'].split())  \n",
        "print(\"Maximum sized length : English \",maxLenEn,\"German \", maxLenFr )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum sized length : English  38 German  41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aZ9oy4BPYEh",
        "colab_type": "code",
        "outputId": "3fdd9924-a303-4456-ec27-83b8de2eacf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# we will split the data to keep 70:30 ratio for training and test data\n",
        "splitData = np.random.rand(len(limitDataset)) <= 0.7\n",
        "trainData = limitDataset[splitData]\n",
        "testData = limitDataset[~splitData]\n",
        "#check the data count in training set and test set\n",
        "print(\"Training Data: \",trainData.shape,\" Test data: \",testData.shape)\n",
        "# Data in to numpy array conversion\n",
        "trainDataNP=trainData.to_numpy()\n",
        "testDataNP=testData.to_numpy()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:  (25882, 2)  Test data:  (11056, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHEh1q55KMLh",
        "colab_type": "text"
      },
      "source": [
        "**Data encoding is done i.e. converting text to ids and add padding to make all sequences of same length. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDokS3TrX3vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataEncoder(allData, lanTokenizer, length):\n",
        "    encodedData = lanTokenizer.texts_to_sequences(allData)\n",
        "    paddedData = pad_sequences(encodedData, maxlen=length, padding='post')\n",
        "    return paddedData\n",
        "\n",
        "trainFr = dataEncoder(trainDataNP[:, 1],tokenizerFr,maxLenFr)\n",
        "trainEn = dataEncoder(trainDataNP[:, 0],tokenizerEn,maxLenEn)\n",
        "testFr = dataEncoder(testDataNP[:, 1],tokenizerFr,maxLenFr)\n",
        "testEn = dataEncoder(testDataNP[:, 0],tokenizerEn,maxLenEn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEBL70vrw7yR",
        "colab_type": "code",
        "outputId": "d1faaa9d-6b0c-4d7d-9d15-66c52b539548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(trainFr.shape, testFr.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25882, 41) (11056, 41)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr1JGCSS2MHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sequence model\n",
        "def sequenceModel(vocabFr, vocabEn, maxFr, maxEn, units):\n",
        "    seqModel = Sequential()\n",
        "    seqModel.add(Embedding(vocabFr, units, input_length=maxFr, mask_zero=True))\n",
        "    seqModel.add(LSTM(units))\n",
        "    seqModel.add(RepeatVector(maxEn))\n",
        "    seqModel.add(LSTM(units, return_sequences=True))\n",
        "    seqModel.add(Dense(vocabEn, activation='softmax'))\n",
        "    return seqModel\n",
        "\n",
        "seqModel = sequenceModel(vocabSizeFr, vocabSizeEn, maxLenFr, maxLenEn, 256)\n",
        "rmsOptimizer = optimizers.RMSprop(lr=0.01)\n",
        "seqModel.compile(optimizer=rmsOptimizer, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sye8mavR44sm",
        "colab_type": "code",
        "outputId": "90e82ec4-81f6-4ed9-b16d-ffb4ce25b792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "modelPrediction = seqModel.fit(trainFr, trainEn.reshape(trainEn.shape[0], trainEn.shape[1], 1),epochs=15, batch_size=256, validation_split = 0.2, verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20705 samples, validate on 5177 samples\n",
            "Epoch 1/15\n",
            "20705/20705 [==============================] - 18s 867us/step - loss: 1.3919 - val_loss: 1.7848\n",
            "Epoch 2/15\n",
            "20705/20705 [==============================] - 16s 788us/step - loss: 0.8565 - val_loss: 2.0639\n",
            "Epoch 3/15\n",
            "20705/20705 [==============================] - 16s 785us/step - loss: 0.7567 - val_loss: 1.8454\n",
            "Epoch 4/15\n",
            "20705/20705 [==============================] - 16s 792us/step - loss: 0.6635 - val_loss: 1.9286\n",
            "Epoch 5/15\n",
            "20705/20705 [==============================] - 16s 788us/step - loss: 0.5785 - val_loss: 1.7782\n",
            "Epoch 6/15\n",
            "20705/20705 [==============================] - 16s 771us/step - loss: 0.5028 - val_loss: 1.8772\n",
            "Epoch 7/15\n",
            "20705/20705 [==============================] - 16s 788us/step - loss: 0.4365 - val_loss: 1.7390\n",
            "Epoch 8/15\n",
            "20705/20705 [==============================] - 16s 778us/step - loss: 0.3771 - val_loss: 1.8549\n",
            "Epoch 9/15\n",
            "20705/20705 [==============================] - 16s 783us/step - loss: 0.3239 - val_loss: 1.9331\n",
            "Epoch 10/15\n",
            "20705/20705 [==============================] - 16s 776us/step - loss: 0.2815 - val_loss: 1.9267\n",
            "Epoch 11/15\n",
            "20705/20705 [==============================] - 16s 787us/step - loss: 0.2458 - val_loss: 1.9394\n",
            "Epoch 12/15\n",
            "20705/20705 [==============================] - 16s 779us/step - loss: 0.2144 - val_loss: 2.0274\n",
            "Epoch 13/15\n",
            "20705/20705 [==============================] - 16s 779us/step - loss: 0.1904 - val_loss: 2.1254\n",
            "Epoch 14/15\n",
            "20705/20705 [==============================] - 16s 785us/step - loss: 0.1692 - val_loss: 2.0555\n",
            "Epoch 15/15\n",
            "20705/20705 [==============================] - 16s 785us/step - loss: 0.1533 - val_loss: 2.0560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUE8e54f54if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get predictions for text data \n",
        "testPrediction = seqModel.predict_classes(testFr.reshape((testFr.shape[0],testFr.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64hf0jpJ8IBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## data decoder Convert mapped words in to normal words\n",
        "def wordConversion(word_index, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == word_index:\n",
        "            return word\n",
        "    return None\n",
        "    \n",
        "def dataDecoder(prediction):\n",
        "    textPredicted=list()\n",
        "    for sentence in prediction:\n",
        "        sentenceConverted = list()\n",
        "        for word_index in range(len(sentence)):\n",
        "            word = wordConversion(sentence[word_index], tokenizerEn)\n",
        "            if word_index > 0:\n",
        "                if (word == wordConversion(sentence[word_index-1], tokenizerEn)) or (word == None):\n",
        "                    sentenceConverted.append('')\n",
        "                else:\n",
        "                    sentenceConverted.append(word)\n",
        "\n",
        "            else:\n",
        "                if(word == None):\n",
        "                    sentenceConverted.append('')\n",
        "                else:\n",
        "                    sentenceConverted.append(word)            \n",
        "\n",
        "        textPredicted.append(' '.join(sentenceConverted))\n",
        "        \n",
        "    return textPredicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhxXezP9vQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calling data decoder for the predictions\n",
        "predictedText = dataDecoder(testPrediction)\n",
        "predictedDataframe = pd.DataFrame({'German text': testData['German'],' Expected text' : testData['English'], 'Predicted text' : predictedText})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSruLeXrG969",
        "colab_type": "text"
      },
      "source": [
        "# ***Data after conversion from German to english i.e. both the expected and predicted english text***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIPzs9tI-Bke",
        "colab_type": "code",
        "outputId": "b9154bef-f9ae-460c-9824-8540eb785fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "\n",
        "predictedDataframe.head(10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>German text</th>\n",
              "      <th>Expected text</th>\n",
              "      <th>Predicted text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>iss auf</td>\n",
              "      <td>eat up</td>\n",
              "      <td>be up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>das kommt nicht in frage</td>\n",
              "      <td>no way</td>\n",
              "      <td>that  my</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>wirklich</td>\n",
              "      <td>really</td>\n",
              "      <td>really</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>sei fair</td>\n",
              "      <td>be fair</td>\n",
              "      <td>be up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>troll dich</td>\n",
              "      <td>go away</td>\n",
              "      <td>keep you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>mach ’ne fliege</td>\n",
              "      <td>go away</td>\n",
              "      <td>go away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>gehen sie weg</td>\n",
              "      <td>go away</td>\n",
              "      <td>get you lost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>leb wohl</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>do you know love                              ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>hilf uns</td>\n",
              "      <td>help us</td>\n",
              "      <td>keep us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>umarme tom</td>\n",
              "      <td>hug tom</td>\n",
              "      <td>tom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  German text  ...                                     Predicted text\n",
              "20                    iss auf  ...          be up                                    \n",
              "51   das kommt nicht in frage  ...        that  my                                   \n",
              "55                   wirklich  ...        really                                     \n",
              "69                   sei fair  ...          be up                                    \n",
              "111                troll dich  ...       keep you                                    \n",
              "114           mach ’ne fliege  ...        go away                                    \n",
              "137             gehen sie weg  ...    get you lost                                   \n",
              "141                  leb wohl  ...  do you know love                              ...\n",
              "148                  hilf uns  ...        keep us                                    \n",
              "156                umarme tom  ...           tom                                     \n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxI95pCaGo_g",
        "colab_type": "text"
      },
      "source": [
        "# ***Using corpus bleu function to calculate the Bleu score for data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTJqNco-_MWj",
        "colab_type": "code",
        "outputId": "0399a110-ea98-409c-9966-344985794e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print('BLEU score using corpus bleu function:',corpus_bleu(testDataNP[:,0], predictedText))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score using corpus bleu function: 0.648951343411966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8vuCXQhIM46",
        "colab_type": "text"
      },
      "source": [
        "## ***Generating the csv file for predicted output***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdSEKp-fIF5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedDataframe.to_csv('predicted.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}